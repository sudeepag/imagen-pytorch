{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20084,"status":"ok","timestamp":1666556995609,"user":{"displayName":"Adiel Felsen","userId":"00629966147769798210"},"user_tz":240},"id":"jWtUrPGNJOuh","outputId":"76dddc1d-1875-43e0-f943-5e10987f81c7"},"outputs":[],"source":["# Install packages\n","# %pip install accelerate click einops einops_exts ema-pytorch fsspec kornia numpy packaging pillow pydantic pytorch-lightning pytorch-warmup sentencepiece torch torchvision transformers tqdm --quiet"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24134,"status":"ok","timestamp":1666557019734,"user":{"displayName":"Adiel Felsen","userId":"00629966147769798210"},"user_tz":240},"id":"fUDDt7OUJav_","outputId":"be4fda40-0ee7-4f32-b524-84050872c52d"},"outputs":[],"source":["# # Mount Google Drive\n","# from google.colab import drive\n","# drive.mount('/content/drive/')\n","\n","# # Copy imagen folder locally\n","# !cp -r /content/drive/MyDrive/imagen ."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5936,"status":"ok","timestamp":1666557025662,"user":{"displayName":"Adiel Felsen","userId":"00629966147769798210"},"user_tz":240},"id":"fInDjtWcJcov","outputId":"46e1bcc3-9b81-4992-ad42-11616b56fe75"},"outputs":[],"source":["# %pip install imagen_pytorch --quiet"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["3a72a8e2d11447d88a5f6c16331f2016","dcb63bc6263f4b04aa457a5b1bd3312f","3b89bd340f6e4bfbb1791630ac13b258","4fbc2cad537641bc97e886767b800a93","829ae82fd8d5413a90526fd4c3c1ea9d","0ad6f35bf23141ea87c41013083329e7","c4182f38768b47b0bd2cfc9a28c177aa","53167828b85e4e699aa540edfd581233","4ec92be8d66145429fe4b0ac9736ff56","996e72cd0d1646ceb60a0f0af7076279","6b35ab445a4146ec972acc8e419ace5b"]},"executionInfo":{"elapsed":6896,"status":"ok","timestamp":1666557032552,"user":{"displayName":"Adiel Felsen","userId":"00629966147769798210"},"user_tz":240},"id":"9a8frMNoZpJl","outputId":"72eea584-c91d-4e8d-d111-e458015156e4"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/adiel/anaconda3/envs/imagen/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import torch\n","from imagen_pytorch import Unet, Imagen, ImagenTrainer"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6717,"status":"ok","timestamp":1666557039257,"user":{"displayName":"Adiel Felsen","userId":"00629966147769798210"},"user_tz":240},"id":"Zm_1eHvmaxk8","outputId":"f5ce209d-6215-44a3-9f16-c70b1870943a"},"outputs":[],"source":["# %pip install import-ipynb --quiet"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1993,"status":"ok","timestamp":1666557041244,"user":{"displayName":"Adiel Felsen","userId":"00629966147769798210"},"user_tz":240},"id":"rsKBVvHvamb3","outputId":"86c911e2-b8f4-493a-b416-190da2fbdea2"},"outputs":[{"name":"stdout","output_type":"stream","text":["importing Jupyter notebook from COCODataset.ipynb\n"]}],"source":["import import_ipynb\n","\n","from COCODataset import COCODataset"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":541,"status":"ok","timestamp":1666557041775,"user":{"displayName":"Adiel Felsen","userId":"00629966147769798210"},"user_tz":240},"id":"bPpM7N_ga9QS","outputId":"297bdf93-2600-424e-b04a-afacfbdda846"},"outputs":[{"name":"stdout","output_type":"stream","text":["The base dimension of your u-net should ideally be no smaller than 128, as recommended by a professional DDPM trainer https://nonint.com/2022/05/04/friends-dont-let-friends-train-small-diffusion-models/\n"]}],"source":["# unet for imagen\n","\n","unet1 = Unet(\n","    dim = 32,\n","    cond_dim = 128,\n","    dim_mults = (1, 2, 4, 8),\n","    num_resnet_blocks = 3,\n","    layer_attns = (False, True, True, True),\n",")\n","\n","# unet2 = Unet(\n","    # dim = 32,\n","    # cond_dim = 128,\n","    # dim_mults = (1, 2, 4, 8),\n","    # num_resnet_blocks = (2, 4, 8, 8),\n","    # layer_attns = (False, False, False, True),\n","    # layer_cross_attns = (False, False, False, True)\n","# )"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["7a439be29a5b4a64baecb4a505ad2076","3f35b5a6cc5e40488cc60f15323af4f6","3e4f311800944fdd9d30b72cde790ff5","978f30c3f5e8437a80ea773b5d542232","171688917cc747c3b30b7f5a5bccba3d","cf924cb367d643e1a858541907c43ff4","5603e1d5b7a04e73b837ea01c0c438d9","ac9bf4b2f81a47bfb386475a901a6e30","c74091e728c744cd98cfe6b99cb66244","4db0b15c439d4958ac0ae854a6cb408a","7d54532cbdfd470585bfe4f483b73ae5"]},"executionInfo":{"elapsed":6770,"status":"ok","timestamp":1666557048538,"user":{"displayName":"Adiel Felsen","userId":"00629966147769798210"},"user_tz":240},"id":"P_-scDWsZqRT","outputId":"66169a6e-8ada-4ba5-e15b-987b76726de6"},"outputs":[],"source":["# imagen, which contains the unets above (base unet and super resoluting ones)\n","imagen = Imagen(\n","    unets = unet1,\n","    text_encoder_name = 't5-base',\n","    image_sizes = 32,\n","    timesteps = 1000,\n","    cond_drop_prob = 0.1\n",").cuda()"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1666557048543,"user":{"displayName":"Adiel Felsen","userId":"00629966147769798210"},"user_tz":240},"id":"SVnVgvwHZw4s"},"outputs":[{"name":"stdout","output_type":"stream","text":["no checkpoints found to load from at ./cp/\n"]}],"source":["# wrap imagen with the trainer class\n","trainer = ImagenTrainer(\n","    imagen, \n","    split_valid_from_train = True,\n","    checkpoint_path = \"./cp/\",\n","    checkpoint_every=5000\n",").cuda()"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":8901,"status":"ok","timestamp":1666557057434,"user":{"displayName":"Adiel Felsen","userId":"00629966147769798210"},"user_tz":240},"id":"IhIY7k9YZzB5"},"outputs":[],"source":["dataset = COCODataset('./data/train2017/train2017', './embeddings', './annotations', \"./paths/im_paths.json\", \"./paths/em_paths.json\", image_size = 32, max_embed_size=32, save_paths=False)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1666557057435,"user":{"displayName":"Adiel Felsen","userId":"00629966147769798210"},"user_tz":240},"id":"TlXNttDeMFIk","outputId":"b40a58b4-991f-4280-94ea-7d2609409085"},"outputs":[{"name":"stdout","output_type":"stream","text":["236936\n"]}],"source":["print(len(dataset))"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1666557057436,"user":{"displayName":"Adiel Felsen","userId":"00629966147769798210"},"user_tz":240},"id":"hT9sLVy-Jn57","outputId":"fdb64546-cb51-4bb1-c76c-bbd1552d8daf"},"outputs":[{"name":"stdout","output_type":"stream","text":["236936\n"]}],"source":["print(len(list(dataset.id_to_empath.keys())))"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1666557057436,"user":{"displayName":"Adiel Felsen","userId":"00629966147769798210"},"user_tz":240},"id":"Cy2Cdi1HZ1sn","outputId":"16f7e6e5-b24d-4fe9-c9f0-6f7231e7b77a"},"outputs":[{"name":"stdout","output_type":"stream","text":["training with dataset of 231012 samples and validating with randomly splitted 5924 samples\n"]}],"source":["trainer.add_train_dataset(dataset, batch_size = 64)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gVMow9BfZmXS","outputId":"6ba46b89-dd9b-4663-fb9b-3100ce200824"},"outputs":[{"name":"stdout","output_type":"stream","text":["0: loss: 0.6646080017089844\n","1: loss: 0.6407820582389832\n","2: loss: 0.6542752981185913\n","3: loss: 0.6021029949188232\n","4: loss: 0.6461031436920166\n","5: loss: 0.6747523546218872\n","6: loss: 0.648411750793457\n","7: loss: 0.5932953357696533\n","8: loss: 0.623455822467804\n","9: loss: 0.601704478263855\n","10: loss: 0.6480996012687683\n","11: loss: 0.6318804621696472\n","12: loss: 0.5791606903076172\n","13: loss: 0.631140410900116\n","14: loss: 0.6463558077812195\n","15: loss: 0.6028473377227783\n","16: loss: 0.6320886611938477\n","17: loss: 0.6787024736404419\n","18: loss: 0.6400778293609619\n","19: loss: 0.6525121331214905\n","20: loss: 0.6381585597991943\n","21: loss: 0.6270104646682739\n","22: loss: 0.6225738525390625\n","23: loss: 0.647109866142273\n","24: loss: 0.6049071550369263\n","25: loss: 0.6363463401794434\n","26: loss: 0.620418131351471\n","27: loss: 0.6227573156356812\n","28: loss: 0.6283382773399353\n","29: loss: 0.6467706561088562\n","30: loss: 0.6446770429611206\n","31: loss: 0.6330771446228027\n","32: loss: 0.6462870836257935\n","33: loss: 0.6344558000564575\n","34: loss: 0.6142666935920715\n","35: loss: 0.5959848761558533\n","36: loss: 0.6193437576293945\n","37: loss: 0.5404569506645203\n","38: loss: 0.6026041507720947\n","39: loss: 0.6050326824188232\n","40: loss: 0.5832931399345398\n","41: loss: 0.614849328994751\n","42: loss: 0.625861406326294\n","43: loss: 0.5900595188140869\n","44: loss: 0.5840016603469849\n","45: loss: 0.5136716365814209\n","46: loss: 0.5847744941711426\n","47: loss: 0.5679906606674194\n","48: loss: 0.5507164001464844\n","49: loss: 0.5575613379478455\n","50: loss: 0.5517525672912598\n","51: loss: 0.5520340204238892\n","52: loss: 0.5506519675254822\n","53: loss: 0.5762057304382324\n","54: loss: 0.5584657192230225\n","55: loss: 0.564568042755127\n","56: loss: 0.5271626710891724\n","57: loss: 0.5330464839935303\n","58: loss: 0.5023816823959351\n","59: loss: 0.5317143201828003\n","60: loss: 0.531171441078186\n","61: loss: 0.557420015335083\n","62: loss: 0.5388649702072144\n","63: loss: 0.5206539630889893\n","64: loss: 0.5320948362350464\n","65: loss: 0.5040774345397949\n","66: loss: 0.5408101081848145\n","67: loss: 0.4975948929786682\n","68: loss: 0.5012692213058472\n","69: loss: 0.509770393371582\n","70: loss: 0.523219645023346\n","71: loss: 0.4772525131702423\n","72: loss: 0.4797323942184448\n","73: loss: 0.4961450695991516\n","74: loss: 0.5039260983467102\n","75: loss: 0.44932040572166443\n","76: loss: 0.4618000090122223\n","77: loss: 0.45701172947883606\n","78: loss: 0.45445287227630615\n","79: loss: 0.41810938715934753\n","80: loss: 0.4479956328868866\n","81: loss: 0.4516511559486389\n","82: loss: 0.45604151487350464\n","83: loss: 0.4446558356285095\n","84: loss: 0.41586998105049133\n","85: loss: 0.4697464406490326\n","86: loss: 0.4616715908050537\n","87: loss: 0.4249194860458374\n","88: loss: 0.4158968925476074\n","89: loss: 0.43748700618743896\n","90: loss: 0.4365672469139099\n","91: loss: 0.40687841176986694\n","92: loss: 0.4215587377548218\n","93: loss: 0.38523152470588684\n","94: loss: 0.4096629023551941\n","95: loss: 0.39872974157333374\n","96: loss: 0.41284292936325073\n","97: loss: 0.42964792251586914\n","98: loss: 0.39444565773010254\n","99: loss: 0.42110979557037354\n"]},{"name":"stderr","output_type":"stream","text":["sampling loop time step: 100%|██████████| 1000/1000 [01:11<00:00, 14.08it/s]\n","1it [01:11, 71.09s/it]\n"]},{"ename":"RuntimeError","evalue":"CUDA out of memory. Tried to allocate 256.00 MiB (GPU 0; 7.79 GiB total capacity; 5.56 GiB already allocated; 260.44 MiB free; 6.02 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn [15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# working training loop\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m200000\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     loss \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mtrain_step(unet_number \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, max_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# if not (i % 50):\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m#     valid_loss = trainer.valid_step(unet_number = 1, max_batch_size = 4)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m#     print(f'valid loss: {valid_loss}')\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/imagen/lib/python3.9/site-packages/imagen_pytorch/trainer.py:590\u001b[0m, in \u001b[0;36mImagenTrainer.train_step\u001b[0;34m(self, unet_number, **kwargs)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_step\u001b[39m(\u001b[39mself\u001b[39m, unet_number \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    589\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_train_iter()\n\u001b[0;32m--> 590\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep_with_dl_iter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_dl_iter, unet_number \u001b[39m=\u001b[39;49m unet_number, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    591\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate(unet_number \u001b[39m=\u001b[39m unet_number)\n\u001b[1;32m    592\u001b[0m     \u001b[39mreturn\u001b[39;00m loss\n","File \u001b[0;32m~/anaconda3/envs/imagen/lib/python3.9/site-packages/imagen_pytorch/trainer.py:608\u001b[0m, in \u001b[0;36mImagenTrainer.step_with_dl_iter\u001b[0;34m(self, dl_iter, **kwargs)\u001b[0m\n\u001b[1;32m    606\u001b[0m dl_tuple_output \u001b[39m=\u001b[39m cast_tuple(\u001b[39mnext\u001b[39m(dl_iter))\n\u001b[1;32m    607\u001b[0m model_input \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl_tuple_output_keywords_names, dl_tuple_output)))\n\u001b[0;32m--> 608\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m{\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_input})\n\u001b[1;32m    609\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n","File \u001b[0;32m~/anaconda3/envs/imagen/lib/python3.9/site-packages/imagen_pytorch/trainer.py:135\u001b[0m, in \u001b[0;36mcast_torch_tensor.<locals>.inner\u001b[0;34m(model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m args, kwargs_values \u001b[39m=\u001b[39m all_args[:split_kwargs_index], all_args[split_kwargs_index:]\n\u001b[1;32m    133\u001b[0m kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mtuple\u001b[39m(\u001b[39mzip\u001b[39m(kwargs_keys, kwargs_values)))\n\u001b[0;32m--> 135\u001b[0m out \u001b[39m=\u001b[39m fn(model, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    136\u001b[0m \u001b[39mreturn\u001b[39;00m out\n","File \u001b[0;32m~/anaconda3/envs/imagen/lib/python3.9/site-packages/imagen_pytorch/trainer.py:961\u001b[0m, in \u001b[0;36mImagenTrainer.forward\u001b[0;34m(self, unet_number, max_batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[39mfor\u001b[39;00m chunk_size_frac, (chunked_args, chunked_kwargs) \u001b[39min\u001b[39;00m split_args_and_kwargs(\u001b[39m*\u001b[39margs, split_size \u001b[39m=\u001b[39m max_batch_size, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    960\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39mautocast():\n\u001b[0;32m--> 961\u001b[0m         loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mimagen(\u001b[39m*\u001b[39;49mchunked_args, unet \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49munet_being_trained, unet_number \u001b[39m=\u001b[39;49m unet_number, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mchunked_kwargs)\n\u001b[1;32m    962\u001b[0m         loss \u001b[39m=\u001b[39m loss \u001b[39m*\u001b[39m chunk_size_frac\n\u001b[1;32m    964\u001b[0m     total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n","File \u001b[0;32m~/anaconda3/envs/imagen/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/anaconda3/envs/imagen/lib/python3.9/site-packages/imagen_pytorch/imagen_pytorch.py:2507\u001b[0m, in \u001b[0;36mImagen.forward\u001b[0;34m(self, images, unet, texts, text_embeds, text_masks, unet_number, cond_images)\u001b[0m\n\u001b[1;32m   2503\u001b[0m         lowres_aug_times \u001b[39m=\u001b[39m repeat(lowres_aug_time, \u001b[39m'\u001b[39m\u001b[39m1 -> b\u001b[39m\u001b[39m'\u001b[39m, b \u001b[39m=\u001b[39m b)\n\u001b[1;32m   2505\u001b[0m images \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresize_to(images, target_image_size)\n\u001b[0;32m-> 2507\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mp_losses(unet, images, times, text_embeds \u001b[39m=\u001b[39;49m text_embeds, text_mask \u001b[39m=\u001b[39;49m text_masks, cond_images \u001b[39m=\u001b[39;49m cond_images, noise_scheduler \u001b[39m=\u001b[39;49m noise_scheduler, lowres_cond_img \u001b[39m=\u001b[39;49m lowres_cond_img, lowres_aug_times \u001b[39m=\u001b[39;49m lowres_aug_times, pred_objective \u001b[39m=\u001b[39;49m pred_objective, p2_loss_weight_gamma \u001b[39m=\u001b[39;49m p2_loss_weight_gamma, random_crop_size \u001b[39m=\u001b[39;49m random_crop_size)\n","File \u001b[0;32m~/anaconda3/envs/imagen/lib/python3.9/site-packages/imagen_pytorch/imagen_pytorch.py:2407\u001b[0m, in \u001b[0;36mImagen.p_losses\u001b[0;34m(self, unet, x_start, times, noise_scheduler, lowres_cond_img, lowres_aug_times, text_embeds, text_mask, cond_images, noise, times_next, pred_objective, p2_loss_weight_gamma, random_crop_size)\u001b[0m\n\u001b[1;32m   2403\u001b[0m         unet_kwargs \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39munet_kwargs, \u001b[39m'\u001b[39m\u001b[39mself_cond\u001b[39m\u001b[39m'\u001b[39m: x_start}\n\u001b[1;32m   2405\u001b[0m \u001b[39m# get prediction\u001b[39;00m\n\u001b[0;32m-> 2407\u001b[0m pred \u001b[39m=\u001b[39m unet\u001b[39m.\u001b[39;49mforward(\n\u001b[1;32m   2408\u001b[0m     x_noisy,\n\u001b[1;32m   2409\u001b[0m     noise_cond,\n\u001b[1;32m   2410\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49munet_kwargs\n\u001b[1;32m   2411\u001b[0m )\n\u001b[1;32m   2413\u001b[0m \u001b[39m# prediction objective\u001b[39;00m\n\u001b[1;32m   2415\u001b[0m \u001b[39mif\u001b[39;00m pred_objective \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnoise\u001b[39m\u001b[39m'\u001b[39m:\n","File \u001b[0;32m~/anaconda3/envs/imagen/lib/python3.9/site-packages/imagen_pytorch/imagen_pytorch.py:1651\u001b[0m, in \u001b[0;36mUnet.forward\u001b[0;34m(self, x, time, lowres_cond_img, lowres_noise_times, text_embeds, text_mask, cond_images, self_cond, cond_drop_prob)\u001b[0m\n\u001b[1;32m   1649\u001b[0m \u001b[39mfor\u001b[39;00m init_block, resnet_blocks, attn_block, upsample \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mups:\n\u001b[1;32m   1650\u001b[0m     x \u001b[39m=\u001b[39m add_skip_connection(x)\n\u001b[0;32m-> 1651\u001b[0m     x \u001b[39m=\u001b[39m init_block(x, t, c)\n\u001b[1;32m   1653\u001b[0m     \u001b[39mfor\u001b[39;00m resnet_block \u001b[39min\u001b[39;00m resnet_blocks:\n\u001b[1;32m   1654\u001b[0m         x \u001b[39m=\u001b[39m add_skip_connection(x)\n","File \u001b[0;32m~/anaconda3/envs/imagen/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/anaconda3/envs/imagen/lib/python3.9/site-packages/imagen_pytorch/imagen_pytorch.py:709\u001b[0m, in \u001b[0;36mResnetBlock.forward\u001b[0;34m(self, x, time_emb, cond)\u001b[0m\n\u001b[1;32m    707\u001b[0m \u001b[39mif\u001b[39;00m exists(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcross_attn):\n\u001b[1;32m    708\u001b[0m     \u001b[39massert\u001b[39;00m exists(cond)\n\u001b[0;32m--> 709\u001b[0m     h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcross_attn(h, context \u001b[39m=\u001b[39;49m cond) \u001b[39m+\u001b[39m h\n\u001b[1;32m    711\u001b[0m h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblock2(h, scale_shift \u001b[39m=\u001b[39m scale_shift)\n\u001b[1;32m    713\u001b[0m h \u001b[39m=\u001b[39m h \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgca(h)\n","File \u001b[0;32m~/anaconda3/envs/imagen/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/anaconda3/envs/imagen/lib/python3.9/site-packages/einops_exts/torch.py:17\u001b[0m, in \u001b[0;36mEinopsToAndFrom.forward\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m reconstitute_kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mtuple\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfrom_einops\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m), shape)))\n\u001b[1;32m     16\u001b[0m x \u001b[39m=\u001b[39m rearrange(x, \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfrom_einops\u001b[39m}\u001b[39;00m\u001b[39m -> \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_einops\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(x, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     18\u001b[0m x \u001b[39m=\u001b[39m rearrange(x, \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_einops\u001b[39m}\u001b[39;00m\u001b[39m -> \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfrom_einops\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mreconstitute_kwargs)\n\u001b[1;32m     19\u001b[0m \u001b[39mreturn\u001b[39;00m x\n","File \u001b[0;32m~/anaconda3/envs/imagen/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/anaconda3/envs/imagen/lib/python3.9/site-packages/imagen_pytorch/imagen_pytorch.py:791\u001b[0m, in \u001b[0;36mCrossAttention.forward\u001b[0;34m(self, x, context, mask)\u001b[0m\n\u001b[1;32m    788\u001b[0m attn \u001b[39m=\u001b[39m attn\u001b[39m.\u001b[39mto(sim\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m    790\u001b[0m out \u001b[39m=\u001b[39m einsum(\u001b[39m'\u001b[39m\u001b[39mb h i j, b h j d -> b h i d\u001b[39m\u001b[39m'\u001b[39m, attn, v)\n\u001b[0;32m--> 791\u001b[0m out \u001b[39m=\u001b[39m rearrange(out, \u001b[39m'\u001b[39;49m\u001b[39mb h n d -> b n (h d)\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    792\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_out(out)\n","File \u001b[0;32m~/anaconda3/envs/imagen/lib/python3.9/site-packages/einops/einops.py:487\u001b[0m, in \u001b[0;36mrearrange\u001b[0;34m(tensor, pattern, **axes_lengths)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mRearrange can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be applied to an empty list\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    486\u001b[0m     tensor \u001b[39m=\u001b[39m get_backend(tensor[\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39mstack_on_zeroth_dimension(tensor)\n\u001b[0;32m--> 487\u001b[0m \u001b[39mreturn\u001b[39;00m reduce(tensor, pattern, reduction\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrearrange\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49maxes_lengths)\n","File \u001b[0;32m~/anaconda3/envs/imagen/lib/python3.9/site-packages/einops/einops.py:410\u001b[0m, in \u001b[0;36mreduce\u001b[0;34m(tensor, pattern, reduction, **axes_lengths)\u001b[0m\n\u001b[1;32m    408\u001b[0m     hashable_axes_lengths \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(\u001b[39msorted\u001b[39m(axes_lengths\u001b[39m.\u001b[39mitems()))\n\u001b[1;32m    409\u001b[0m     recipe \u001b[39m=\u001b[39m _prepare_transformation_recipe(pattern, reduction, axes_lengths\u001b[39m=\u001b[39mhashable_axes_lengths)\n\u001b[0;32m--> 410\u001b[0m     \u001b[39mreturn\u001b[39;00m _apply_recipe(recipe, tensor, reduction_type\u001b[39m=\u001b[39;49mreduction)\n\u001b[1;32m    411\u001b[0m \u001b[39mexcept\u001b[39;00m EinopsError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    412\u001b[0m     message \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m Error while processing \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m-reduction pattern \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(reduction, pattern)\n","File \u001b[0;32m~/anaconda3/envs/imagen/lib/python3.9/site-packages/einops/einops.py:239\u001b[0m, in \u001b[0;36m_apply_recipe\u001b[0;34m(recipe, tensor, reduction_type)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(added_axes) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    238\u001b[0m     tensor \u001b[39m=\u001b[39m backend\u001b[39m.\u001b[39madd_axes(tensor, n_axes\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(axes_reordering) \u001b[39m+\u001b[39m \u001b[39mlen\u001b[39m(added_axes), pos2len\u001b[39m=\u001b[39madded_axes)\n\u001b[0;32m--> 239\u001b[0m \u001b[39mreturn\u001b[39;00m backend\u001b[39m.\u001b[39;49mreshape(tensor, final_shapes)\n","File \u001b[0;32m~/anaconda3/envs/imagen/lib/python3.9/site-packages/einops/_backends.py:84\u001b[0m, in \u001b[0;36mAbstractBackend.reshape\u001b[0;34m(self, x, shape)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreshape\u001b[39m(\u001b[39mself\u001b[39m, x, shape):\n\u001b[0;32m---> 84\u001b[0m     \u001b[39mreturn\u001b[39;00m x\u001b[39m.\u001b[39;49mreshape(shape)\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 256.00 MiB (GPU 0; 7.79 GiB total capacity; 5.56 GiB already allocated; 260.44 MiB free; 6.02 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}],"source":["# working training loop\n","for i in range(200000):\n","    loss = trainer.train_step(unet_number = 1, max_batch_size = 64)\n","\n","    print(f'{i}: loss: {loss}')\n","\n","    # if not (i % 50):\n","    #     valid_loss = trainer.valid_step(unet_number = 1, max_batch_size = 4)\n","    #     print(f'valid loss: {valid_loss}')\n","\n","    if not ((i+1) % 5000) and trainer.is_main: # is_main makes sure this can run in distributed\n","        images = trainer.sample(texts = [\n","            'A red school bus parked in a parking lot',\n","            'A blue school bus parked in a parking lot',\n","            'The decadent chocolate dessert is on the table',\n","            'A bowl of bananas is on the table'\n","        ], cond_scale = 3., return_pil_images = True)\n","        images[0].save(f'./out/sample-redbus-{i // 1000}.png')\n","        images[1].save(f'./out/sample-bluebus-{i // 1000}.png')\n","        images[2].save(f'./out/sample-chocolate-{i // 1000}.png')\n","        images[3].save(f'./out/sample-bananas-{i // 1000}.png')\n","\n","        # trainer.save(f'./cp/1-{i}.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOt+qxf1+/yqAyfy98lRd7D","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.13 ('imagen')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"35fae3f18e38468e6b55db8705bddd2952e8e2d99941fc5d0b3ea6fe4be361f8"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"0ad6f35bf23141ea87c41013083329e7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"171688917cc747c3b30b7f5a5bccba3d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a72a8e2d11447d88a5f6c16331f2016":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dcb63bc6263f4b04aa457a5b1bd3312f","IPY_MODEL_3b89bd340f6e4bfbb1791630ac13b258","IPY_MODEL_4fbc2cad537641bc97e886767b800a93"],"layout":"IPY_MODEL_829ae82fd8d5413a90526fd4c3c1ea9d"}},"3b89bd340f6e4bfbb1791630ac13b258":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_53167828b85e4e699aa540edfd581233","max":605,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4ec92be8d66145429fe4b0ac9736ff56","value":605}},"3e4f311800944fdd9d30b72cde790ff5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac9bf4b2f81a47bfb386475a901a6e30","max":1199,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c74091e728c744cd98cfe6b99cb66244","value":1199}},"3f35b5a6cc5e40488cc60f15323af4f6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf924cb367d643e1a858541907c43ff4","placeholder":"​","style":"IPY_MODEL_5603e1d5b7a04e73b837ea01c0c438d9","value":"Downloading: 100%"}},"4db0b15c439d4958ac0ae854a6cb408a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ec92be8d66145429fe4b0ac9736ff56":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4fbc2cad537641bc97e886767b800a93":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_996e72cd0d1646ceb60a0f0af7076279","placeholder":"​","style":"IPY_MODEL_6b35ab445a4146ec972acc8e419ace5b","value":" 605/605 [00:00&lt;00:00, 16.3kB/s]"}},"53167828b85e4e699aa540edfd581233":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5603e1d5b7a04e73b837ea01c0c438d9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6b35ab445a4146ec972acc8e419ace5b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7a439be29a5b4a64baecb4a505ad2076":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3f35b5a6cc5e40488cc60f15323af4f6","IPY_MODEL_3e4f311800944fdd9d30b72cde790ff5","IPY_MODEL_978f30c3f5e8437a80ea773b5d542232"],"layout":"IPY_MODEL_171688917cc747c3b30b7f5a5bccba3d"}},"7d54532cbdfd470585bfe4f483b73ae5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"829ae82fd8d5413a90526fd4c3c1ea9d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"978f30c3f5e8437a80ea773b5d542232":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4db0b15c439d4958ac0ae854a6cb408a","placeholder":"​","style":"IPY_MODEL_7d54532cbdfd470585bfe4f483b73ae5","value":" 1.20k/1.20k [00:00&lt;00:00, 10.2kB/s]"}},"996e72cd0d1646ceb60a0f0af7076279":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac9bf4b2f81a47bfb386475a901a6e30":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4182f38768b47b0bd2cfc9a28c177aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c74091e728c744cd98cfe6b99cb66244":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cf924cb367d643e1a858541907c43ff4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dcb63bc6263f4b04aa457a5b1bd3312f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ad6f35bf23141ea87c41013083329e7","placeholder":"​","style":"IPY_MODEL_c4182f38768b47b0bd2cfc9a28c177aa","value":"Downloading: 100%"}}}}},"nbformat":4,"nbformat_minor":0}
