{"cells":[{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":914,"status":"ok","timestamp":1666556463159,"user":{"displayName":"Adiel Felsen","userId":"00629966147769798210"},"user_tz":240},"id":"PmtlVT7JKcFt","outputId":"940f3aee-6d5a-460b-f5a6-9633c71dd39e"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'google.colab'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn [29], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      2\u001b[0m   \u001b[38;5;66;03m# Mount Google Drive\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      4\u001b[0m   drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m   \u001b[38;5;66;03m# Copy imagen folder locally\u001b[39;00m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"]}],"source":["if __name__ == \"__main__\":\n","  # Mount Google Drive\n","  from google.colab import drive\n","  drive.mount('/content/drive/')\n","\n","  # Copy imagen folder locally\n","  !cp -r /content/drive/MyDrive/imagen ."]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":253,"status":"ok","timestamp":1666556490925,"user":{"displayName":"Adiel Felsen","userId":"00629966147769798210"},"user_tz":240},"id":"rkU7x4w5Vd4M"},"outputs":[],"source":["from cgitb import text\n","from pathlib import Path\n","from functools import partial\n","\n","import torch\n","from torch import nn\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms as T, utils\n","import torch.nn.functional as F\n","\n","from PIL import Image\n","import numpy as np\n","\n","import json\n","import glob\n","\n","\n","\n","def exists(val):\n","    return val is not None\n","\n","def cycle(dl):\n","    while True:\n","        for data in dl:\n","            yield data\n","\n","def convert_image_to(img_type, image):\n","    if image.mode != img_type:\n","        return image.convert(img_type)\n","    return image\n","\n","class COCODataset(Dataset):\n","    def __init__(\n","        self,\n","        image_folder,\n","        embedding_folder,\n","        annotations_folder,\n","        im_path_file,\n","        em_path_file,\n","        image_size,\n","        max_embed_size,\n","        exts = ['jpg', 'jpeg', 'png', 'tiff'],\n","        convert_image_to_type = None,\n","        save_paths = False\n","    ):\n","        super().__init__()\n","\n","        self.image_folder = image_folder\n","        self.image_size = image_size\n","        self.max_embed_size = max_embed_size\n","\n","        self.embedding_folder = embedding_folder\n","\n","        if save_paths:\n","          self.save_id_path_dicts(im_path_file, em_path_file, exts)          \n","\n","        self.load_id_path_dicts(im_path_file, em_path_file)\n","        \n","        with open(f\"{annotations_folder}/captions_train2017.json\", 'r') as f:\n","            self.annotations = json.load(f)\n","\n","        self.annotations['annotations'] = self.annotations['annotations'][0::5] + self.annotations['annotations'][1::5]\n","            \n","        convert_fn = partial(convert_image_to, convert_image_to_type) if exists(convert_image_to_type) else nn.Identity()\n","\n","        self.transform = T.Compose([\n","            T.Lambda(convert_fn),\n","            T.Resize(image_size),\n","            T.RandomHorizontalFlip(),\n","            T.CenterCrop(image_size),\n","            T.ToTensor()\n","        ])\n","\n","        self.embed_keys = list(self.id_to_empath.keys())\n","\n","\n","    def load_id_path_dicts(self, id_to_im_path_file, id_to_em_path_file):\n","        with open(id_to_im_path_file, \"r\") as f:\n","            id_to_impath = json.load(f)\n","            self.id_to_impath = {int(k):v for k,v in id_to_impath.items()}\n","        with open(id_to_em_path_file, \"r\") as f:\n","            id_to_empath = json.load(f)\n","            self.id_to_empath = {int(k):v for k,v in id_to_empath.items()}\n","\n","        # maximum = -1\n","        # for i, path in enumerate(self.id_to_empath.values()):\n","        #     if not (i%10000):\n","        #         print(i)\n","        #     embed = torch.load(path)\n","        #     maximum = max(embed.shape[1], maximum)\n","        # print(maximum)\n","\n","    def save_id_path_dicts(self, id_to_im_path_file, id_to_em_path_file, exts):\n","        em_paths = glob.glob(self.embedding_folder + \"/*/*.pt\")\n","        em_ids = [int(str(path).split('_')[-1].split('.')[0]) for path in em_paths]\n","        id_to_empath = {idn: path for idn, path in zip(em_ids, em_paths)}\n","\n","        with open(id_to_em_path_file, 'w') as f:\n","            json.dump(id_to_empath, f)\n","\n","        im_paths = []\n","        for ext in exts:\n","            im_paths.extend(glob.glob(f\"{self.image_folder}-*/*.{ext}\"))\n","        print(len(im_paths))\n","        #[p for ext in exts for p in Path(f'{self.image_folder}').glob(f'**/*.{ext}')]\n","        print(im_paths[0])\n","        im_ids = [int(str(path).split('/')[-1].split('.')[0]) for path in im_paths]\n","        id_to_impath = {idn: str(path) for idn, path in zip(im_ids, im_paths)}\n","\n","        with open(id_to_im_path_file, 'w') as f:\n","            json.dump(id_to_impath, f)\n","\n","\n","\n","    def __len__(self):\n","        return len(self.embed_keys)\n","\n","    def __getitem__(self, index):\n","        # annotation = self.annotations['annotations'][index]   \n","        # print(annotation['image_id'], annotation['id']) \n","        # embed_id = annotation['id']\n","\n","        embed_id = self.embed_keys[index]\n","\n","        embed_path = self.id_to_empath[embed_id]\n","        text_embeds = torch.load(embed_path)\n","        text_embeds = text_embeds[:,:self.max_embed_size,:]\n","        text_embeds = F.pad(input = text_embeds, pad=(0, 0, 0, self.max_embed_size-text_embeds.shape[1], 0, 0), mode='constant', value=0)\n","        text_embeds = text_embeds[0,:,:]\n","\n","        # image_id = annotation['image_id']\n","        image_id = int(embed_path.split('/')[-1].split('_')[0])\n","\n","        img_path = self.id_to_impath[image_id]\n","        img = Image.open(img_path)\n","        img = np.array(img)\n","        \n","        if len(img.shape) == 2:\n","            img = img[..., np.newaxis]\n","            img = np.stack((img,)*3, axis=-1)\n","        if len(img.shape) == 4:\n","            img = img[:,:,0,:]\n","\n","\n","        img = Image.fromarray(img)\n","\n","        return self.transform(img), text_embeds\n","\n"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":2020,"status":"ok","timestamp":1666556495011,"user":{"displayName":"Adiel Felsen","userId":"00629966147769798210"},"user_tz":240},"id":"eRklM4k1RyLn"},"outputs":[{"name":"stdout","output_type":"stream","text":["236936\n"]}],"source":["if __name__ == \"__main__\":\n","    data = COCODataset('./data/train2017/train2017', './embeddings', './annotations', \"./paths/im_paths.json\", \"./paths/em_paths.json\", image_size = 64, max_embed_size=32, save_paths=False)\n","    print(len(data))"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"executionInfo":{"elapsed":2098,"status":"ok","timestamp":1666556532457,"user":{"displayName":"Adiel Felsen","userId":"00629966147769798210"},"user_tz":240},"id":"DZkQlK6Sae4F","outputId":"4f1cb093-fb17-441d-a222-080e77323fd9"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([3, 64, 64]) torch.Size([32, 768])\n","torch.Size([32, 768])\n"]}],"source":["if __name__ == \"__main__\":\n","  img, embed = data[0]\n","  print(embed.shape)\n","  # from google.colab.patches import cv2_imshow\n","  # cv2_imshow(np.moveaxis(img.numpy()*255, 0,-1))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":869,"status":"ok","timestamp":1666237938447,"user":{"displayName":"Adiel Felsen","userId":"00629966147769798210"},"user_tz":240},"id":"VKxcnvwiXPrP","outputId":"9103552b-9de1-4393-f256-f4df277b36f2"},"outputs":[{"name":"stdout","output_type":"stream","text":["cp: cannot stat './paths': No such file or directory\n"]}],"source":["if __name__ == \"__main__\":\n","  !cp -r ./imagen/paths /content/drive/MyDrive/imagen/paths"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNvZTKfxBqFWEwgw/lCuB2G","collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3.9.13 ('imagen')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"35fae3f18e38468e6b55db8705bddd2952e8e2d99941fc5d0b3ea6fe4be361f8"}}},"nbformat":4,"nbformat_minor":0}
